{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "09.11. hw_Liza (city_smells).ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Liza-Kadetova/HseCL_kadetova/blob/master/09_11_hw_Liza_(city_smells).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8Rk-uvmIvLC",
        "colab_type": "text"
      },
      "source": [
        "у нас есть текст, которых лежит в файле city_smells.txt. Давайте проведем с ним элементарные количественные исследования: можно, например, узнать, сколько в тексте уникальных слов, размер самого длинного предложения и тд. Чтобы работать с текстом, который лежит в файле, нам надо:\n",
        "\n",
        "Открыть файл (не забудьте о режиме открытия и энкодинге)\n",
        "Прочитать его\n",
        "Сохранить текст в переменную, с которой можно работать дальше\n",
        "Предобработка текста: удалить пунктуацию, свести текст к нижнему регистру\n",
        "\n",
        "Что можно сделать с текстом: (пункты на выбор, минимум один)\n",
        "\n",
        "определить среднюю длину слова в тексте\n",
        "определить среднюю длину предложения в тексте\n",
        "посчитать, во сколько раз самое длинное предложение длиннее самого короткого (такое же можно сделать со словами)\n",
        "(не убирая пунктуацию) - среднее количество пунктуационных знаков в предложении\n",
        "количество уникальных слов и пророрция общему количеству слов в тексте\n",
        "что-то еще, что Вы сами захотите поисследовать\n",
        "Запишите результат Вашего мини-исследования в новый файл, добавьте его и (отдельный) файл с кодом в Ваш репозиторий.\n",
        "\n",
        "Удачи! Дедлайн - суббота, 16 ноября."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWhjpMB8GTKP",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Задача 1: количество символов в тексте"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilb8XxKXmef9",
        "colab_type": "code",
        "outputId": "ee420bf5-de06-4fc5-9d65-42407bc36ee0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "with open('city_smells.txt', 'r') as file: #считаем, сколько всего знаков в строке (тексте)\n",
        "  print(len(file.read()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4332\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wshe-G6EGkk9",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Задача 2: самое длинное слово в тексте\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oE0GIyog8Ul",
        "colab_type": "code",
        "outputId": "708a1b83-fc84-4f4f-d21a-95768387aca8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import string\n",
        "with open('city_smells.txt', 'r') as file1:\n",
        "  txt1 = file1.read()\n",
        "txt1 = txt1.lower()\n",
        "txt1 = txt1.translate(str.maketrans('','',string.punctuation))\n",
        "txt1 = txt1.translate(str.maketrans('','','—«»'))\n",
        "list1 = txt1.split()\n",
        "print('Слов в тексте:',len(list1)) # получили количество слов в тексте\n",
        "set1=set(list1)\n",
        "print('Уникальных слов в тексте:',len(set1)) #получили количество уникальных слов в тексте\n",
        "list2 = [len(i) for i in set1] \n",
        "print('Самое длинное слово в этом тексте состоит из', max(list2), 'символов')\n",
        "for i in set1:\n",
        "  if len(i)>16:\n",
        "    print('И это слово: \\\"'+i+'\\\"')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Слов в тексте: 601\n",
            "Уникальных слов в тексте: 401\n",
            "Самое длинное слово в этом тексте состоит из 17 символов\n",
            "И это слово: \"картографирования\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaV4KTmwGvJ_",
        "colab_type": "text"
      },
      "source": [
        "Задача 3: самое длинное предложение "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4Xup3TDvq6m",
        "colab_type": "code",
        "outputId": "c7b887ad-d18e-4ee8-b006-e9f464cc9f1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "import string\n",
        "from string import digits\n",
        "import re\n",
        "list666=[]\n",
        "i = 1\n",
        "with open('city_smells.txt', 'r') as file3:\n",
        "  txt3 = file3.read()\n",
        "#print(txt3)\n",
        "txt3=re.sub('\\d.\\d','XXX', txt3) #иначе также разбивает по точке во float\n",
        "txt4 = re.split(r'\\.|:\\n|\\?', txt3) #видимо, в тексте выброшена картинка, осталось двоеточие вместо точки\n",
        "#print(txt4) #txt4 теперь это список, можно проверить\n",
        "print(len(txt4), 'предложения в тексте') #количество предложений (=элементов) в тексте (списке), но в них пока есть тире и цифры, которые считаются как слова\n",
        "for line in txt4:\n",
        "  line = line.translate(str.maketrans('','',string.punctuation)) #не ловит тире\n",
        "  line = line.translate(str.maketrans('—',' ',))\n",
        "  line = line.translate(str.maketrans('','',string.digits)) #выкинули цифры, чтобы не считать словами\n",
        "  newline = line.split()\n",
        "  #print(i, len(newline), newline) #out: номер предложения-списка, количество слов в нем\n",
        "  i=i+1\n",
        "  list666.append(len(newline))\n",
        "  if len(newline)>35:\n",
        "    print('Самое длинное предложение:', line)\n",
        "#print(list666) #список всех длин\n",
        "print('В нем', max(list666), 'слов') #количество слов в как бы самом длинном как бы предложеним в тексте"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "34 предложения в тексте\n",
            "Самое длинное предложение:  Массив данных о городских запахах сравнили и с такими данными и сделали вывод о том что данные о более низком качестве воздуха с примесями положительно коррелируют с такими категориями как «выбросывыхлопы» и отрицательно   с категорией «природа»\n",
            "В нем 36 слов\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WceCQztbHEN6",
        "colab_type": "text"
      },
      "source": [
        "Задача 4: транслитирировать текст"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmHELNRQnxxx",
        "colab_type": "code",
        "outputId": "381fce35-cd6a-4e76-f053-c47b1b015584",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        }
      },
      "source": [
        "import string\n",
        "file2 = open('city_smells.txt', 'r')\n",
        "file2 = file2.read()\n",
        "trans = {'а': 'a', 'б': 'b', 'в':'v', 'г':'g', 'д':'d','е':'e','ё':'yo', 'ж':'zh', \n",
        "         'з':'z','и':'i','й':'j','к':'k','л':'l','м':'m','н':'n','о':'o','п':'p',\n",
        "         'р':'r','с':'s','т':'t','у':'u','ф':'f','х':'x','ц':'c','ч':'ch','ш':'sh',\n",
        "         'щ':'shh','ъ':'``','ы':'y','ь':'`','э':'e`','ю':'yu','я':'ya',\n",
        "         'А': 'A', 'Б': 'B', 'В':'V', 'Г':'G', 'Д':'D','Е':'E','Ё':'YO', 'Ж':'ZH', \n",
        "         'З':'Z','И':'I','Й':'J','К':'K','Л':'L','М':'M','Н':'N','О':'O','П':'P',\n",
        "         'Р':'R','С':'S','Т':'T','У':'U','Ф':'F','Х':'X','Ц':'C','Ч':'CH','Ш':'SH',\n",
        "         'Щ':'SHH','Ъ':'``','Ы':'Y','Ь':'`','Э':'E`','Ю':'YU','Я':'YA'}\n",
        "def translit(t):\n",
        "  t = t.translate(str.maketrans(trans))\n",
        "  return t\n",
        "fff = translit(file2)\n",
        "print(fff)\n",
        "file2.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pomnite zapax svezhevypechennogo xleba na dozhdlivoj ulochke iz toj bulochnoj, v kotoruyu vy zaxodili v proshlom mesyace?\n",
            "A kak on smeshalsya s zapaxom smolotogo kofe?\n",
            "A zapax svezheskoshennoj travy v parke osvezhayushhim vecherom posle zharkogo dnya?\n",
            "Zapaxi ezheminutno soprovozhdayut nas v gorode, no oni mimoletny i nevidimy, poe`tomu chasto uskol`zayut ot vnimaniya urbanistov i issledovatelej gorodskoj sredy.\n",
            "Gruppa uchenyx iz raznyx universitetov mira v ramkax proekta Smelly Maps reshila ispravit` e`tu nespravedlivost` i zanyalas` issledovaniem gorodskix zapaxov.\n",
            "Samyj pervyj i vazhnyj vopros, s kotorym oni stolknulis` — otkuda brat` dannye dlya raboty? Odin iz ochevidnyx otvetov — sobirat` dannye na meste pri pomoshhi tak nazyvaemyx «smell walks».\n",
            "Princip prost: gruppa dobrovol`cev idet po marshrutu i zapisyvaet vse zapaxi, kotorye chuvstvuet po puti, otmechaya konkretnye mesta na karte.\n",
            "Na osnove takix progulok i neskol`kix issledovanij byl sostavlen «slovar` zapaxov», kotoryj sostoyal iz vsex slov, kotorymi dobrovol`cy opisyvali zapaxi vo vremya progulki.\n",
            "Prosto, e`ffektivno i deshevo.\n",
            "No u takogo metoda est` nedostatki: na obxod dazhe nebol`shogo goroda neskol`ko desyatkov dobrovol`cev potratit ochen` mnogo vremeni, a esli my xotim eshhe i rassmotret` dinamiku, e`tot sposob ne podxodit sovsem.\n",
            "Ostaetsya obratit`sya k dobrovol`no sobiraemym i publikuemym v seti bol`shim dannym, a imenno k dannym social`nyx setej.\n",
            "Vzyat` 17 millionov fotografij iz Flickr, 5.1 milliona snimkov iz publichnyx akkauntov Instagram i 5.3 milliona tvitov iz Tvittera, kazhdyj iz kotoryx obladaet geotegom — i s e`tim uzhe mozhno rabotat`.\n",
            "Nabor dannyx iz Tvittera byl ochishhen ot retvitov i otvetov, posle chego v summe dlya analiza bylo gotovo 1.7 milliona tvitov.\n",
            "Teksty tvitov i podpisej k fotografiyam byl rasparsen, i iz vsego massiva slov byli otobrany tol`ko te, kotorye imeyut otnoshenie k zapaxam.\n",
            "Na osnove e`tix dannyx byl postroen vzveshennyj graf svyazej mezhdu slovami, v vershinax kotorogo zakrepleny sami slova, a ves rebra sootvetstvuet kolichestvu raz, kogda e`ti dva slova vstrechayutsya v odnom tekste. Takoj analiz vyyavil neskol`ko chetko opredelennyx kategorij zapaxov, naprimer, «prirodnye», «industrial`nye», «eda», «vybrosy/vyxlopy», «musor».\n",
            "Vnutri kategorij inogda mozhno bylo vydelit` podkategorii i opredelit` samye chasto vstrechayushhiesya slova-metki e`toj kategorii.\n",
            "Sxemu e`tix kategorij mozhno uvidet` nizhe.\n",
            "Cveta vybrany ne prosto tak.\n",
            "Issledovateli nashli svyazi mezhdu zapaxami i cvetami, preobladayushhimi na analiziruemyx fotografiyax.\n",
            "Zapaxi takzhe svyazany s negativnymi ili pozitivnymi e`mociyami, naprimer, kategoriya «musor» budet polozhitel`no korrelirovat` s negativnymi e`mociyami, otvrashheniem i pechal`yu, no otricatel`no — s radost`yu.\n",
            "\n",
            "V sovremennyx gorodax sushhestvuyut programmy monitoringa kachestva vozduxa, pozvolyayushhie gorodskim sluzhbam operativno reagirovat` na anomalii, a obychnym gorozhanam sledit` za sostavom vozduxa, kotorym oni dyshat. Massiv dannyx o gorodskix zapaxax sravnili i s takimi dannymi i sdelali vyvod o tom, chto dannye o bolee nizkom kachestve vozduxa s primesyami polozhitel`no korreliruyut s takimi kategoriyami, kak «vybrosy/vyxlopy», i otricatel`no — s kategoriej «priroda».\n",
            "Takoj vyvod kazhetsya logichnym, no teper` on dokazan nauchno.\n",
            "\n",
            "Po geotegam issledovateli sdelali interaktivnye karty, gde mozhno uznat`, chem paxnut ulicy takix gorodov mira, kak London i Barselona (dva pervyx goroda, dlya kotoryx byli sobrany i proanalizirovany dannye).\n",
            "Est` takzhe karty Madrida, Rima, Milana, N`yu-Jorka i eshhe shesti krupnyx amerikanskix gorodov.\n",
            "Avtory utverzhdayut, chto spisok budet popolnyat`sya i dal`she.\n",
            "\n",
            "Dlya kartografirovaniya ispol`zovalis` otkrytye dannye Open Street Map, vnutri kotoryx byli vydeleny segmenty ulic ot perekrestka do perekrestka, k kotorym byli privyazany geotegi original`nyx dannyx.\n",
            "Na stranice proekta, puteshestvuya po interaktivnym kartam, mozhno posmotret` sootnoshenie zapaxov po kazhdomu segmentu, naprimer, v Barselone na ulice Bal`mes zapax edy preobladaet:\n",
            "\n",
            "Vmeste zapaxi skladyvayutsya v kompleksnyj i slozhnyj landshaft, unikal`nyj dlya kazhdogo goroda, i on nuzhdaetsya v issledovanii tak zhe, kak i landshaft vizual`nyj ili zvukovoj.\n",
            "Kstati, po zaprosu ot avtorov mozhno poluchit` takzhe dannye, na kotoryx osnovyvalsya proekt, esli est` zhelanie issledovat` ix samostoyatel`no.\n",
            "\n",
            "Istochniki:\n",
            "Stranica proekta Smelly Maps\n",
            "Interaktivnye karty proekta\n",
            "Nelli Burceva\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cK1nUpEzsD-t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}